---
title: "Parametric Bootstrapping"
author: "CJ Carani, Dylan Hunt and Matt Kaznikov"
date: "02-21-2024"
output: pdf_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
library(tidyverse)
library(GGally)
library(knitr)
library(gridExtra)
library(MASS)
library(gridExtra)  
library(mnormt) 
library(lme4) 
library(lmerTest)
library(knitr) 
library(kableExtra)
library(tidyverse)
library(Matrix)
```

Comparing LME models using Parametric Bootstrapping
```{r}
Airbnb <- read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/airbnb.csv")
```

```{r}
# Model 1 - LME Comparison REDUCED MODEL
reduced <- lm(price ~ bedrooms + room_type, data = Airbnb)
summary(M1)
```

```{r}
# Record estimates from the original model (M1)
b0 <- coef(reduced)[1]
b1 <- coef(reduced)[2]
b2 <- coef(reduced)[3]
b3 <- coef(reduced)[4]
sigma <- summary(reduced)$sigma
nreps <- 1000

# Initialize vectors for bootstrap results
bootstrap_b0 <- numeric(nreps)
bootstrap_b1 <- numeric(nreps)
bootstrap_b2 <- numeric(nreps)
bootstrap_b3 <- numeric(nreps)
bootstrap_sigma <- numeric(nreps)

# Copy the original data for simulation
B_Data <- Airbnb

# Simulate data and fit model
for (i in 1:nreps) {
  # Simulate new data
  B_Data$SimPrice <- b0 + (b1*B_Data$bedrooms) + b2 + b3 + rnorm(n = nrow(Airbnb), mean = 0, sd = sigma)
  
  # Fit model to simulated data
  Mb1 <- lm(SimPrice ~ bedrooms + room_type, data = B_Data)
  
  # Record coefficients and sigma from the model on simulated data
  bootstrap_b0[i] <- coef(Mb1)[1]
  bootstrap_b1[i] <- coef(Mb1)[2]
  bootstrap_b2[i] <- coef(Mb1)[3]
  bootstrap_b3[i] <- coef(Mb1)[4]
  bootstrap_sigma[i] <- summary(Mb1)$sigma
}

# Create a data frame with bootstrap results
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_b2, bootstrap_b3, bootstrap_sigma)

# View the summary of bootstrap results
summary(Bootstrap_Results)
```

```{r}
# Model 2 - LME Comparison FULL MODEL
full <- lmer(data = Airbnb, price ~ bedrooms + room_type + overall_satisfaction + (1|neighborhood))
summary(full)
```

```{r}
# Record estimates from the original model
b0 <- fixef(full)[1]
b1 <- fixef(full)[2]
b2 <- fixef(full)[3]
b3 <- fixef(full)[4]
b4 <- fixef(full)[5]
sigma <- summary(full)$sigma
nreps <- 1000

# Initialize vectors for bootstrap results
bootstrap_b0 <- numeric(nreps)
bootstrap_b1 <- numeric(nreps)
bootstrap_b2 <- numeric(nreps)
bootstrap_b3 <- numeric(nreps)
bootstrap_b4 <- numeric(nreps)
bootstrap_sigma <- numeric(nreps)

# Copy the original data for simulation
B_Data <- Airbnb

# Simulate data and fit model
for (i in 1:nreps) {
  # Simulate new data
  B_Data$SimPrice <- b0 + (b1*B_Data$bedrooms) + b2 + b3 + (b4*B_Data$overall_satisfaction) + rnorm(n = nrow(Airbnb), mean = 0, sd = sigma)
  
  # Fit mixed-effects model to simulated data
  Mb2 <- lmer(SimPrice ~ bedrooms + room_type + overall_satisfaction + (1|neighborhood), data = B_Data)
  
  # Record fixed effects and sigma from the model on simulated data
  bootstrap_b0[i] <- fixef(Mb2)[1]
  bootstrap_b1[i] <- fixef(Mb2)[2]
  bootstrap_b2[i] <- fixef(Mb2)[3]
  bootstrap_b3[i] <- fixef(Mb2)[4]
  bootstrap_b4[i] <- fixef(Mb2)[5]  
  bootstrap_sigma[i] <- summary(Mb2)$sigma
}

# Create a data frame with bootstrap results
Bootstrap_Results_M2 <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_b2, bootstrap_b3, bootstrap_b3, bootstrap_sigma)

# View the summary of bootstrap results
summary(Bootstrap_Results_M2)
```

```{r}
anova(full, reduced)
```
```{r}
set.seed(02272022)
# record estimates from reduced model
b0 <- reduced$coefficients[1]
b1 <- reduced$coefficients[2]
b2 <- reduced$coefficients[3]
b3 <- reduced$coefficients[4]
sigma <- summary(reduced)$sigma
nreps <- 1000
bootstrap_F <- c(rep(NA, nreps))
B_Data <- Airbnb
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data from reduced model
B_Data <- B_Data %>% mutate(SimPrice = b0 + b1*yearnew + rnorm(n= nrow(derby.df), mean=0, sd=sigma))
Mb_Reduced <- lm(data=B_Data, SimPrice~yearnew)   #fit reduced model to simulated data
Mb_Full <- lm(data=B_Data, SimPrice ~ yearnew + fast + yearnew:fast)   #fit full model to simulated data
bootstrap_F[i] <- anova(Mb_Full, Mb_Red)$F[2]
}
Bootstrap_Results <- data.frame(bootstrap_F)
```

Data for a model without many observations (Elephants)

### Background
"Bootstrapping methods are a numerical approach to generating confidence intervals that use either resampled data or simulated data to estimate the sampling distribution of the maximum likelihood parameter estimates"



### Data
```{r}
elephants <- read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/elephant.csv")
```

```{r}
E_M1 <- lm(MATINGS ~ AGE, data = elephants)
summary(E_M1)

elephants <- elephants %>% mutate(age2 = AGE*AGE)
E_M2 <- lm(MATINGS ~ AGE + age2, data = elephants)
summary(E_M2)
```

#Bootstrap for Model 1 Estimates
```{r}
# record estimates from the model
b0 <- E_M1$coefficients[1]
b1 <- E_M1$coefficients[2]
sigma <- summary(E_M1)$sigma
nreps <- 10000
bootstrap_b0 <- c(rep(NA, nreps))
bootstrap_b1 <- c(rep(NA, nreps))
bootstrap_sigma <- c(rep(NA, nreps))
E_Data <- elephants
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data
E_Data <- E_Data %>% mutate(SimMatings = b0 + b1*AGE + rnorm(n= nrow(elephants), mean=0, sd=sigma))
Mb <- lm(data=E_Data, SimMatings~AGE)   #fit model to simulated data
bootstrap_b0[i] <- Mb$coefficients[1]        #record b0 from model on simulated data
bootstrap_b1[i] <- Mb$coefficients[2]        #record b1 from model on simulated data
bootstrap_sigma[i] <- summary(Mb)$sigma      #record sigma from model on simulated data
}
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_sigma)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color="red")
p1
```

```{r}
quantile(bootstrap_b1, c(.025, .975))
```

```{r}
quantile(bootstrap_b2, c(.025, .975))
```

```{r}
anova(E_M1, E_M2)
```


```{r}
set.seed(02272022)
# record estimates from reduced model
b0 <- E_M1$coefficients[1]
b1 <- E_M1$coefficients[2]
sigma <- summary(E_M1)$sigma
nreps <- 10000
bootstrap_F <- c(rep(NA, nreps))
B_Data <- elephants
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data from reduced model
B_Data <- B_Data %>% mutate(SimMatings = b0 + b1*AGE + rnorm(n= nrow(elephants), mean=0, sd=sigma))
Mb_Red <- lm(data=B_Data, SimMatings~AGE)   #fit reduced model to simulated data
Mb_Full <- lm(data=B_Data, SimMatings ~ AGE + age2)   #fit full model to simulated data
bootstrap_F[i] <- anova(Mb_Full, Mb_Red)$F[2]
}
Bootstrap_Results <- data.frame(bootstrap_F)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_F)) + geom_histogram() + geom_vline(xintercept = 0.4187, color="red", linetype="dotted", size=2) 
p1
```



```{r}
## Multilevel Generalized Linear Model for Bootstrapping

# Reading in Basketball Refs Data
refdata <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/basketball0910.csv")
# Model 1 with random slope, but no random Effect
glm1 <- glmer(foul.home ~ foul.diff + (1|game), family = binomial(link="logit"), data = refdata)
# Model 2 with a random slope and a random effect for foul.diff
glm2 <- glmer(foul.home ~ foul.diff + (foul.diff|game), family = binomial(link="logit"), data = refdata)

# Compare Model's
anova(glm1,glm2)
```

```{r}
# Bootstrapping
set.seed(02272022)
nreps <- 1000
ChiSq <- rep(NA, nreps)
for(i in 1:nreps){
SimData <- drop(simulate(glm1))  # this command simulates data directly from a model
glm1B <-refit(glm1, newresp=SimData)  # refits glm1 to simulated data
glm2B <-refit(glm2, newresp=SimData)  # refits glm2 to simulated data
ChiSq[i] <- anova(glm1B,glm2B)$Chisq[2]
}
ChiSq<- write.csv(ChiSq, file="ChiSq.csv")
```

```{r}
ChiSq <- read.csv("ChiSq.csv")
p <- ggplot(data=data.frame(ChiSq), aes(x=x)) + geom_histogram() + 
  geom_vline(xintercept = 5.4682, color="red", linetype="dotted", size=2) 
p
```

```{r}
mean(ChiSq>5.4682)
```

Level 1 Variables:
  Observational Unit: Fouls
  Variables:
    foul.num, foul.home, foul.vis, foul.diff, score.diff, lead.vis, lead.home, previous.foul.home,          previous.foul.vis, foul.type, personal, offensive, time
Level 2 Variables:
  Observational Unit: Game
  Variables:
    Game, Date, Visitor, Home Team
    

=======
# Background

# Methods
LME Model Comparison
  Our goal was to view how parametric bootstrapping can help us compare linear mixed effects models. We crated a full model with three variables and a random slope and wanted to compare that to a less complicated reduced model with two variables. One way to compare is by comparing the AIC's of the two models and the p-value for the full model. 
  But, another more foolproof way is by generating a bootstrap for each model and comparing the two sets of bootstrapped data. Bootstrapping provides the opportunity to negate any outlier data points, by generating a set number of data points randomly. This allows our estimates to be more exact and allows us to better view which model truly fits the data better.
  The first step for comparing LME models was creating the full model comprising of the variables bedrooms, room_type, and overall_satisfaction with a random slope for neighborhood. The random slope is added to account for the random derivation of price for each neighborhood. This model serves as our more complex model for the act of comparing a reduced model to a more complicated model using parametric bootstrapping.
  Then, we created a reduced model comprising of the variables bedrooms and room_type, without a random slope variables. This model is predicted to not account for as much variability in the model, but will help us determine if our full model is too complicated.

CJ:

Dylan:

# Data

# Results

# Conclusions
