---
title: "Parametric Bootstrapping"
author: "CJ Carani, Dylan Hunt and Matt Kaznikov"
date: "02-21-2024"
output: pdf_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
library(tidyverse)
library(GGally)
library(knitr)
library(gridExtra)
library(MASS)
library(gridExtra)  
library(mnormt) 
library(lme4) 
library(lmerTest)
library(knitr) 
library(kableExtra)
library(tidyverse)
library(Matrix)
```

# Background:

W.A. Nelson, renowned American statistician, from the Encyclopedia of Ecology states, "Bootstrapping methods are a numerical approach to generating confidence intervals that use either resampled data or simulated data to estimate the sampling distribution of the maximum likelihood parameter estimates". In addition to generating confidence intervals, bootstrapping is used often for data where there is a lack of observations or concerns about model assumptions (like normal distribution or skewed data). Bootstrapping solves this issue by using a technique called sampling with replacement. Sampling with replacement is taking the original data and randomly sampling observations while putting the data back into the original dataset. These steps are then repeated thousands of times to generate a simulated dataset. The idea is that this simulated data will provide us with better reasoning on how well our models perform and which model to use by creating a comparison with the use of the new data. While non-parametric bootstrapping bases the simulated data on the original data, parametric bootstrapping simulates data based on a model’s estimates. The steps to use parametric bootstrapping are as follows:

1) Fit a model to the original dataset and record that model's parameters using their estimated values. 
2) Next using the recorded estimated parameter values simulate many datasets. 
3) For each newly created dataset, record each of the estimated parameters. 
4) Then calculate statistics that are important for your conclusions. (p-values, F-statistic, t-statistics, etc.) 
5) Create confidence intervals based off of the simulated values. 

There are multiple reasons that we would want to use simulated data based on a model, but the most common one is when we have confidence in a model but doubt a model’s standard error terms. While if we had confidence in both the standard error and the model we would use the theory based R estimates. And, if we had faith in the standard error but not in the model we would use non-parametric bootstrapping. We must have faith in the model for parametric bootstrapping because parametric bootstrapping operates on the assumption that the estimates follow a normal distribution. This assumption comes from the fact that the simulated values are generated based on the fitted model. This simulation allows us to generate confidence intervals that are more precise and trustworthy than the original data.

# Methods:

For each of the three models we use parametric bootstrapping to improve our datasets or to improve our models. The steps used to complete this follow the steps highlighted within our background section. First we create a model using the original dataset using the typical functions (lm and glmer). Following this step, we record the parameter estimates and standard deviation. Next we create vectors of a certain size, x (10,000) that will be used to hold the parameter estimates and standard deviations for each of the simulated models. Then we create a duplicate dataset using the original dataset. We are now able to begin our for loop that will run for x numbers of times. Now that we are within our for loop we want to begin to create our new simulated data. We use a mutate command to change the duplicated dataset to hold simulated data instead of the original data. Following, our model is run on the new simulated data then those estimates are collected within the vectors we created earlier. After the for loop is done we use the collected simulated data estimates to run tests to understand how well our models are and their estimated parameters.

# Data/Results:

## Linear Model Comparison:
```{r}
Airbnb <- read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/airbnb.csv")
```
### Model 1: Reduced Model
```{r}
# Model 1 - LME Comparison REDUCED MODEL
reduced <- lm(price ~ bedrooms + room_type, data = Airbnb)
summary(reduced)
```
### Model 1: Bootstrapping
```{r}
# Record estimates from the original model (M1)
b0 <- coef(reduced)[1]
b1 <- coef(reduced)[2]
b2 <- coef(reduced)[3]
b3 <- coef(reduced)[4]
sigma <- summary(reduced)$sigma
nreps <- 1000

# Initialize vectors for bootstrap results
bootstrap_b0 <- numeric(nreps)
bootstrap_b1 <- numeric(nreps)
bootstrap_b2 <- numeric(nreps)
bootstrap_b3 <- numeric(nreps)
bootstrap_sigma <- numeric(nreps)

# Copy the original data for simulation
B_Data <- Airbnb

# Simulate data and fit model
for (i in 1:nreps) {
  # Simulate new data
  B_Data$SimPrice <- b0 + (b1*B_Data$bedrooms) + b2 + b3 + rnorm(n = nrow(Airbnb), mean = 0, sd = sigma)
  
  # Fit model to simulated data
  Mb1 <- lm(SimPrice ~ bedrooms + room_type, data = B_Data)
  
  # Record coefficients and sigma from the model on simulated data
  bootstrap_b0[i] <- coef(Mb1)[1]
  bootstrap_b1[i] <- coef(Mb1)[2]
  bootstrap_b2[i] <- coef(Mb1)[3]
  bootstrap_b3[i] <- coef(Mb1)[4]
  bootstrap_sigma[i] <- summary(Mb1)$sigma
}

# Create a data frame with bootstrap results
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_b2, bootstrap_b3, bootstrap_sigma)

# View the summary of bootstrap results
summary(Bootstrap_Results)
```
### Model 1: Confidence Interval for Bootstrapped b0
```{r}
#For Reduced Model
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color="red") + geom_vline(xintercept = 47.342, color = "green", linetype="dotted", size=2)  + ggtitle("Confidence Intervals for Bootstrapped b1") + ylab("Count") + xlab("Bootstrapped b1")
p1

quantile(bootstrap_b1, c(.025, .975))
```
### Model 2: Full Model
```{r}
# Model 2 - LME Comparison FULL MODEL
full <- lm(data = Airbnb, price ~ bedrooms + room_type + overall_satisfaction + reviews)
summary(full)
```
### Model 2: Bootstrapping
```{r}
# Record estimates from the original model
b0 <- coef(full)[1]
b1 <- coef(full)[2]
b2 <- coef(full)[3]
b3 <- coef(full)[4]
b4 <- coef(full)[5]
b5 <- coef(full)[6]
sigma <- summary(full)$sigma
nreps <- 1000

# Initialize vectors for bootstrap results
bootstrap_b0 <- numeric(nreps)
bootstrap_b1 <- numeric(nreps)
bootstrap_b2 <- numeric(nreps)
bootstrap_b3 <- numeric(nreps)
bootstrap_b4 <- numeric(nreps)
bootstrap_b5 <- numeric(nreps)
bootstrap_sigma <- numeric(nreps)

# Copy the original data for simulation
B_Data <- Airbnb

# Simulate data and fit model
for (i in 1:nreps) {
  # Simulate new data
  B_Data$SimPrice <- b0 + (b1*B_Data$bedrooms) + b2 + b3 + (b4*B_Data$overall_satisfaction) + b5 + rnorm(n = nrow(Airbnb), mean = 0, sd = sigma)
  
  # Fit mixed-effects model to simulated data
  Mb2 <- lm(SimPrice ~ bedrooms + room_type + overall_satisfaction + reviews, data = B_Data)
  
  # Record fixed effects and sigma from the model on simulated data
  bootstrap_b0[i] <- coef(Mb2)[1]
  bootstrap_b1[i] <- coef(Mb2)[2]
  bootstrap_b2[i] <- coef(Mb2)[3]
  bootstrap_b3[i] <- coef(Mb2)[4]
  bootstrap_b4[i] <- coef(Mb2)[5]  
  bootstrap_b5[i] <- coef(Mb2)[5] 
  bootstrap_sigma[i] <- summary(Mb2)$sigma
}

# Create a data frame with bootstrap results
Bootstrap_Results_M2 <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_b2, bootstrap_b3, bootstrap_b4, bootstrap_b5, bootstrap_sigma)

# View the summary of bootstrap results
summary(Bootstrap_Results_M2)
```
### Model 2: Confidence Intervals for Bootstrapped b1
```{r}
#For Full Model
p2 <- ggplot(data=Bootstrap_Results_M2, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color="red") + geom_vline(xintercept = 47.76056, color = "green", linetype="dotted", size=2) + ggtitle("Confidence Intervals for Bootstrapped b1") + ylab("Count") + xlab("Bootstrapped b1")
p2

quantile(bootstrap_b1, c(.025, .975))
```
### ANOVA Test
```{r}
anova(full, reduced)
```

```{r}
M_Red <- lm(price ~ bedrooms + room_type, data = Airbnb)
M_Full <- lm(price ~ bedrooms + room_type + overall_satisfaction + reviews, data=Airbnb)
```
### Bootstrapping F-Statistic
```{r}
set.seed(02272022)
# record estimates from reduced model
b0 <- M_Red$coefficients[1]
b1 <- M_Red$coefficients[2]
b2 <- M_Red$coefficients[3]
b3 <- M_Red$coefficients[4]
sigma <- summary(M_Red)$sigma
nreps <- 10000
bootstrap_F <- c(rep(NA, nreps))
B_Data <- Airbnb
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data from reduced model
B_Data <- B_Data %>% mutate(SimPrice = b0 + b1*bedrooms + b2 + b3 + rnorm(n= nrow(Airbnb), mean=0, sd=sigma))
Mb_Red <- lm(data=B_Data, SimPrice ~ bedrooms + room_type)   #fit reduced model to simulated data
Mb_Full <- lm(data=B_Data, SimPrice ~ bedrooms + room_type + overall_satisfaction + reviews)   #fit full model to simulated data
bootstrap_F[i] <- anova(Mb_Full, Mb_Red)$F[2]
}
Bootstrap_Results_f_stat <- data.frame(bootstrap_F)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results_f_stat, aes(x=bootstrap_F)) + geom_histogram() + geom_vline(xintercept = 19.864, color="red", linetype="dotted", size=2) + ggtitle("Bootstrapped F-Statistic Distribution") + ylab("Bootstrapped F-Statistic")
p1

mean(bootstrap_F>19.864)
```
### Linear Model Comparison Results:

For our first model we used the Airbnb data to test the overall Airbnb price as seen in class. We had a reduced model where we only had bedrooms and room_type and a full model where we also added two extra explanatory variables of overall_satisfaction and reviews.
After our models were made, we wanted to understand the reliability of the relationship between Airbnb pricing and the number of bedrooms. To conduct this, we tested parametric bootstrapping of our b1 variable among both models and received confidence intervals in return. For the reduced model we received a 95% confidence interval ranging from 42.67896 to 51.96590, and for the full model it ranged from 42.63542 to 52.69015. We also added a green dotted line in each of the bootstrapping b1 plots for our estimated b1 from the original models. As expected, this estimate is in the center of the distribution which reaffirms that our data was generated from the models. This displays how bootstrapping simulates data based on our model estimates and how we would expect a bell curve with our estimate in the center.
After this, we conducted bootstrapping on the F statistic to compare the goodness of fit between the two models for 10,000 resamples. The observed F-statistic value proved to be statistically significant due to the right distribution of the F-statistics. What this tells us is that the full model (with two extra explanatory variables) is very unlikely to have occurred by chance. This conclusion is also consistent with what we saw in our investigation where variables like overall_satisfaction which was added in the second model is highly correlated with price.

## Model without Large Dataset and Comparison:

```{r}
elephants <- read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/elephant.csv")
```
### Summary of Model 1 & Model 2
```{r}
# Generate Model for Elephant dataset
E_M1 <- lm(MATINGS ~ AGE, data = elephants)
summary(E_M1)

elephants <- elephants %>% mutate(age2 = AGE*AGE)
E_M2 <- lm(MATINGS ~ AGE + age2, data = elephants)
summary(E_M2)
```

### Model 1: Bootstrapping
```{r}
#Record estimates and standard deviation from E_M1 model
b0 <- E_M1$coefficients[1]
b1 <- E_M1$coefficients[2]
sigma <- summary(E_M1)$sigma

#Choose how many iterations to run
nreps <- 10000

#Create vectors that hold estimates from Simulation
bootstrap_b0 <- c(rep(NA, nreps))
bootstrap_b1 <- c(rep(NA, nreps))
bootstrap_sigma <- c(rep(NA, nreps))

#Duplicate data set for Simulation to follow
E_Data <- elephants
#Begin for loop
for (i in 1:nreps){
   #Simulate new data using standard deviation 
E_Data <- E_Data %>% mutate(SimMatings = b0 + b1*AGE + rnorm(n= nrow(elephants), mean=0, sd=sigma))
Mb <- lm(data=E_Data, SimMatings~AGE)        #Fit model to simulated data
bootstrap_b0[i] <- Mb$coefficients[1]        #Record b0 from model on simulated data
bootstrap_b1[i] <- Mb$coefficients[2]        #Record b1 from model on simulated data
bootstrap_sigma[i] <- summary(Mb)$sigma      #Record sigma from model on simulated data
}
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_sigma)

summary(Bootstrap_Results)
```

### Model 2: Confidence Intervals for Bootstrapped b1
```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color="red") + ggtitle("Confidence Intervals for Bootstrapped b1") + ylab("Bootstrapped b1")
p1
```

```{r}
quantile(bootstrap_b1, c(.025, .975))
```
### ANOVA Test
```{r}
anova(E_M1, E_M2)
```
### Bootstrapping F-Statistic
```{r}
set.seed(02272022)
# record estimates from reduced model
b0 <- E_M1$coefficients[1]
b1 <- E_M1$coefficients[2]
sigma <- summary(E_M1)$sigma
nreps <- 10000
bootstrap_F <- c(rep(NA, nreps))
B_Data <- elephants
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data from reduced model
B_Data <- B_Data %>% mutate(SimMatings = b0 + b1*AGE + rnorm(n= nrow(elephants), mean=0, sd=sigma))
Mb_Red <- lm(data=B_Data, SimMatings~AGE)   #fit reduced model to simulated data
Mb_Full <- lm(data=B_Data, SimMatings ~ AGE + age2)   #fit full model to simulated data
bootstrap_F[i] <- anova(Mb_Full, Mb_Red)$F[2] 
}
Bootstrap_Results <- data.frame(bootstrap_F)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_F)) + geom_histogram() + geom_vline(xintercept = 0.4187, color="red", linetype="dotted", size=2) 
p1
```
### Model without Large Dataset and Comparison Results:

To showcase a dataset that is not significantly large, we used the elephants dataset by Poole(1989) with matings as a response variable, as a dataset without a large amount of data. The major reason for using this dataset is because of its lack of data which makes it a prime example to use parametric bootstrapping. We are concerned about the estimates for the parameters as well as its F-statistic because of the low number of observations. In E_M1, for every additional year of age for an elephant, on average we expect to see the number of matings increase by 0.2. In E_M2, for every additional year of age for an elephant, we expect on average the number of matings to quadratically increase by a factor of 0.0058. The bootstrap confidence interval in the first histogram shows that the estimated parameter based on the real data is significant when compared against the bootstrapped data. The second histogram created is used to compare the F-statistic of the full model to the bootstrapping data. The F-statistic is very common which does not give us evidence that the full model is better than the reduced model. Our results are consistent with the results from class because in both examples, a quadratic term age^2 is not enough to create a significant model. 

## Model Comparison for Multilevel GLM:

### Summary of GLM1 & GLM2:
```{r}
## Multilevel Generalized Linear Model for Bootstrapping

# Reading in Basketball Refs Data
refdata <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/basketball0910.csv")
# Model 1 with random slope, but no random Effect
glm1 <- glmer(foul.home ~ foul.diff + (1|game), family = binomial(link="logit"), data = refdata)
summary(glm1)
# Model 2 with a random slope and a random effect for foul.diff
glm2 <- glmer(foul.home ~ foul.diff + (foul.diff|game),family = binomial(link="logit") , data = refdata)
summary(glm2)
```

### ANOVA Test
```{r}
# Compare Model's
anova(glm1,glm2)
```

### Bootstrapping Chisq
```{r}
# Bootstrapping
set.seed(02272022)
nreps <- 1000
ChiSq <- rep(NA, nreps)
for(i in 1:nreps){
SimData <- drop(simulate(glm1))  # this command simulates data directly from a model
glm1B <-refit(glm1, newresp=SimData)  # refits glm1 to simulated data
glm2B <-refit(glm2, newresp=SimData)  # refits glm2 to simulated data
ChiSq[i] <- anova(glm1B,glm2B)$Chisq[2]
}
ChiSq<- write.csv(ChiSq, file="ChiSq.csv")
```

```{r}
ChiSq <- read.csv("ChiSq.csv")
p <- ggplot(data=data.frame(ChiSq), aes(x=x)) + geom_histogram() + 
  geom_vline(xintercept = 5.4682, color="red", linetype="dotted", size=2) + xlab("ChiSq") + ggtitle("ChiSq Distribution")
p
```

### Simulation Based P-Value
```{r}
mean(ChiSq$x>5.4682)
```

### Model Comparison for Multilevel GLM Results:

To display model comparison for a multilevel generalized linear model we used the basketball referees dataset with the goal of finding the odds of a home team getting called for a foul.
From using parametric bootstrapping we get a simulated P-value of 0.037. This P-Value is smaller than the previously observed P-value. This result is consistent with the idea that when boundary constraints are an issue in estimating variance and correlation of random effects, theory based P-value tests are too conservative leading to P-values that are estimated higher than they actually occur. Our simulated P-value supports this hypothesis that our above P-value was likely too large due to a conservative approach to calculating the P-values in the ANOVA test. The simulated P-value also tells us that we do have enough evidence to say that our full model is better than our reduced model because the p-value is lower than 0.05. Thus, we can say that the addition of a random effect for foul differential is proven to be beneficial in modeling the odds a foul is called on a home team. This is consistent with our notes and discussion in class that it is clear that the addition of the random slope term of the foul differential makes a difference and is warranted.

# Conclusions:

Parametric Bootstrapping is useful for generating simulated data from model estimates to solve problems that occur due to dataset size, issues with assumptions, or comparing models. This method of bootstrapping can be used on various different types of models. One of the more useful ways to use parametric bootstrapping is by using it to generate additional data to test various models to see which one is more useful for explaining a given dataset. We used this in all three of our examples and then used parametric bootstrapping to estimate the f-statistic and chi squared values. Parametric bootstrapping is very useful when we believe in the model, but do not believe in the standard error formulas. This is because parametric bootstrapping assumes that our simulated values follow a normal distribution because the data is based on a model. Non-parametric bootstrapping is useful when we believe in the standard error formulas, but not the model. This does not assume a normal distribution because we are generating our data by sampling with replacement. Overall, bootstrapping can be very useful when we doubt our confidence intervals, do not have enough data, or have doubts about model assumptions. But, parametric bootstrapping provides another way to fix these problems when we believe in our model and want to have our simulated data follow a normal distribution.

# References: 

https://www.sciencedirect.com/topics/earth-and-planetary-sciences/bootstrapping#:~:text=Parametric%20bootstrapping%20works%20as%20follows,the%20most%20likely%20parameter%20estimates
https://stat455-w22.github.io/stat455-w22-notes/multilevel-generalized-linear-models.html#parametric-bootstrapping
https://bookdown.org/roback/bookdown-BeyondMLR/ch-GLMM.html#cs:refs
