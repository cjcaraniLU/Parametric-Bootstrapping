---
title: "Parametric Bootstrapping"
author: "CJ Carani, Dylan Hunt and Matt Kaznikov"
date: "02-21-2024"
output: pdf_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, fig.height = 3, fig.width = 6)
library(tidyverse)
library(GGally)
library(knitr)
library(gridExtra)
library(MASS)
library(gridExtra)  
library(mnormt) 
library(lme4) 
library(lmerTest)
library(knitr) 
library(kableExtra)
library(tidyverse)
library(Matrix)
```

Comparing LME models using Parametric Bootstrapping
```{r}
Airbnb <- read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/airbnb.csv")
```

```{r}
# Model 1 - LME Comparison REDUCED MODEL
M1 <- lm(price ~ bedrooms + room_type, data = Airbnb)
summary(M1)
```

```{r}
# Record estimates from the original model (M1)
b0 <- coef(M1)[1]
b1 <- coef(M1)[2]
b2 <- coef(M1)[3]
sigma <- summary(M1)$sigma
nreps <- 1000

# Initialize vectors for bootstrap results
bootstrap_b0 <- numeric(nreps)
bootstrap_b1 <- numeric(nreps)
bootstrap_b2 <- numeric(nreps)
bootstrap_b3 <- numeric(nreps)
bootstrap_sigma <- numeric(nreps)

# Copy the original data for simulation
B_Data <- Airbnb

# Simulate data and fit model
for (i in 1:nreps) {
  # Simulate new data
  B_Data$SimPrice <- b0 + (b1*B_Data$bedrooms) + b2 + b3 + rnorm(n = nrow(Airbnb), mean = 0, sd = sigma)
  
  # Fit model to simulated data
  Mb <- lm(SimPrice ~ bedrooms + room_type, data = B_Data)
  
  # Record coefficients and sigma from the model on simulated data
  bootstrap_b0[i] <- coef(Mb)[1]
  bootstrap_b1[i] <- coef(Mb)[2]
  bootstrap_b2[i] <- coef(Mb)[3]
  bootstrap_b3[i] <- coef(Mb)[4]
  bootstrap_sigma[i] <- summary(Mb)$sigma
}

# Create a data frame with bootstrap results
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_b2, bootstrap_b3, bootstrap_sigma)

# View the summary of bootstrap results
summary(Bootstrap_Results)
```

```{r}
# Model 2 - LME Comparison FULL MODEL
full <- lmer(data = Airbnb, price ~ bedrooms + room_type + overall_satisfaction + (1|neighborhood))
summary(full)
```

```{r}
# Record estimates from the original model
b0 <- fixef(full)[1]
b1 <- fixef(full)[2]
b2 <- fixef(full)[3]
b3 <- fixef(full)[4]
b4 <- fixef(full)[5]
sigma <- summary(full)$sigma
nreps <- 1000

# Initialize vectors for bootstrap results
bootstrap_b0 <- numeric(nreps)
bootstrap_b1 <- numeric(nreps)
bootstrap_b2 <- numeric(nreps)
bootstrap_b3 <- numeric(nreps)
bootstrap_b4 <- numeric(nreps)
bootstrap_sigma <- numeric(nreps)

# Copy the original data for simulation
B_Data <- Airbnb

# Simulate data and fit model
for (i in 1:nreps) {
  # Simulate new data
  B_Data$SimPrice <- b0 + (b1*B_Data$bedrooms) + b2 + b3 + (b4*B_Data$overall_satisfaction) + rnorm(n = nrow(Airbnb), mean = 0, sd = sigma)
  
  # Fit mixed-effects model to simulated data
  Mb <- lmer(SimPrice ~ bedrooms + room_type + overall_satisfaction + (1|neighborhood), data = B_Data)
  
  # Record fixed effects and sigma from the model on simulated data
  bootstrap_b0[i] <- fixef(Mb)[1]
  bootstrap_b1[i] <- fixef(Mb)[2]
  bootstrap_b2[i] <- fixef(Mb)[3]
  bootstrap_b3[i] <- fixef(Mb)[4]
  bootstrap_b4[i] <- fixef(Mb)[5]  
  bootstrap_sigma[i] <- summary(Mb)$sigma
}

# Create a data frame with bootstrap results
Bootstrap_Results_M2 <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_b2, bootstrap_b3, bootstrap_b3, bootstrap_sigma)

# View the summary of bootstrap results
summary(Bootstrap_Results_M2)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b0)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b0, c(.025, .975)), color="red") + xlab("b0 Estimates") + ggtitle("Distribution of Bootstrapped b0")
p1
```

```{r}
kable(quantile(bootstrap_b1, c(.025, .975)))
```

```{r}


```

```{r}


```

Data for a model without many observations (Elephants)

### Background
"Bootstrapping methods are a numerical approach to generating confidence intervals that use either resampled data or simulated data to estimate the sampling distribution of the maximum likelihood parameter estimates"



### Data

```{r}
elephants <- read_csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/elephant.csv")
```

```{r}
E_M1 <- lm(MATINGS ~ AGE, data = elephants)
summary(E_M1)

elephants <- elephants %>% mutate(age2 = AGE*AGE)
E_M2 <- lm(MATINGS ~ AGE + age2, data = elephants)
summary(E_M2)
```
#Bootstrap for Model 1 Estimates
```{r}
# record estimates from the model
b0 <- E_M1$coefficients[1]
b1 <- E_M1$coefficients[2]
sigma <- summary(E_M1)$sigma
nreps <- 10000
bootstrap_b0 <- c(rep(NA, nreps))
bootstrap_b1 <- c(rep(NA, nreps))
bootstrap_sigma <- c(rep(NA, nreps))
E_Data <- elephants
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data
E_Data <- E_Data %>% mutate(SimMatings = b0 + b1*AGE + rnorm(n= nrow(elephants), mean=0, sd=sigma))
Mb <- lm(data=E_Data, SimMatings~AGE)   #fit model to simulated data
bootstrap_b0[i] <- Mb$coefficients[1]        #record b0 from model on simulated data
bootstrap_b1[i] <- Mb$coefficients[2]        #record b1 from model on simulated data
bootstrap_sigma[i] <- summary(Mb)$sigma      #record sigma from model on simulated data
}
Bootstrap_Results <- data.frame(bootstrap_b0, bootstrap_b1, bootstrap_sigma)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_b1)) + geom_histogram() + geom_vline(xintercept=quantile(bootstrap_b1, c(.025, .975)), color="red")
p1
```

```{r}
quantile(bootstrap_b1, c(.025, .975))
```

```{r}
quantile(bootstrap_b2, c(.025, .975))
```

```{r}
anova(E_M1, E_M2)
```


```{r}
set.seed(02272022)
# record estimates from reduced model
b0 <- E_M1$coefficients[1]
b1 <- E_M1$coefficients[2]
sigma <- summary(E_M1)$sigma
nreps <- 10000
bootstrap_F <- c(rep(NA, nreps))
B_Data <- elephants
# simulate data and fit model
for (i in 1:nreps){
   # simulate new data from reduced model
B_Data <- B_Data %>% mutate(SimMatings = b0 + b1*AGE + rnorm(n= nrow(elephants), mean=0, sd=sigma))
Mb_Red <- lm(data=B_Data, SimMatings~AGE)   #fit reduced model to simulated data
Mb_Full <- lm(data=B_Data, SimMatings ~ AGE + age2)   #fit full model to simulated data
bootstrap_F[i] <- anova(Mb_Full, Mb_Red)$F[2]
}
Bootstrap_Results <- data.frame(bootstrap_F)
```

```{r}
p1 <- ggplot(data=Bootstrap_Results, aes(x=bootstrap_F)) + geom_histogram() + geom_vline(xintercept = 0.4187, color="red", linetype="dotted", size=2) 
p1
```



```{r}
## Multilevel Generalized Linear Model for Bootstrapping

# Reading in Basketball Refs Data
refdata <- read.csv("https://raw.githubusercontent.com/proback/BeyondMLR/master/data/basketball0910.csv")
# Model 1 with random slope, but no random Effect
glm1 <- glmer(foul.home ~ foul.diff + (1|game), family = binomial(link="logit"), data = refdata)
# Model 2 with a random slope and a random effect for foul.diff
glm2 <- glmer(foul.home ~ foul.diff + (foul.diff|game), family = binomial(link="logit"), data = refdata)

# Compare Model's
anova(glm1,glm2)
```

```{r}
# Bootstrapping
set.seed(02272022)
nreps <- 1000
ChiSq <- rep(NA, nreps)
for(i in 1:nreps){
SimData <- drop(simulate(glm1))  # this command simulates data directly from a model
glm1B <-refit(glm1, newresp=SimData)  # refits glm1 to simulated data
glm2B <-refit(glm2, newresp=SimData)  # refits glm2 to simulated data
ChiSq[i] <- anova(glm1B,glm2B)$Chisq[2]
}
ChiSq<- write.csv(ChiSq, file="ChiSq.csv")
```

```{r}
ChiSq <- read.csv("ChiSq.csv")
p <- ggplot(data=data.frame(ChiSq), aes(x=x)) + geom_histogram() + 
  geom_vline(xintercept = 5.4682, color="red", linetype="dotted", size=2) 
p
```

```{r}
mean(ChiSq>5.4682)
```

Level 1 Variables:
  Observational Unit: Fouls
  Variables:
    foul.num, foul.home, foul.vis, foul.diff, score.diff, lead.vis, lead.home, previous.foul.home,          previous.foul.vis, foul.type, personal, offensive, time
Level 2 Variables:
  Observational Unit: Game
  Variables:
    Game, Date, Visitor, Home Team
    

=======
# Background

# Methods
Kaz:
  Our goal was to view how parametric bootstrapping can help us compare linear mixed effects models. Linear mixed effects models allow us to account for random effects or random slopes. Our second model in the comparison includes a random slope so that we can study if a random slope is helpful to include for our AirBnb Dataset.

CJ:

Dylan:

# Data

# Results

# Conclusions
